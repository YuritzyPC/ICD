{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Data Wrangling\n##### with pandas Cheat Sheet http://pandas.pydata.org\n\n## Tidy Data \n#### A foundation for wrangling in pandas\n#### In a tidy data set: \n##### Each variable is saved in its own column. \n##### Each observation is saved in its own row.\n#### Tidy data complements pandasâ€™s vectorized operations. pandas will automatically preserve observations as you manipulate variables. No other format works as intuitively with pandas.\n\n## Cretaing DataFrames",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd                           #Import Pandas\n\ndf = pd.DataFrame(\n\n{\"a\" : [4, 5, 6],\n\"b\" : [7, 8, 9],\n\"c\" : [10, 11, 12]},\nindex = [1, 2, 3])                            #Specify values for each column.\n\ndf = pd.DataFrame(\n[[4, 7, 10],\n[5, 8, 11],\n[6, 9, 12]],\nindex=[1, 2, 3],\ncolumns=['a', 'b', 'c'])                      #Specify values for each row.\n\ndf = pd.DataFrame(\n    {\"a\" : [4 ,5, 6],\n     \"b\" : [7, 8, 9],\n     \"c\" : [10, 11, 12]},\n index = pd.MultiIndex.from_tuples(\n    [('d', 1), ('d', 2),\n    ('e', 2)], names=['n', 'v']))             #Create DataFrame with a MultiIndex\n \n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Method Chaining\n##### Most pandas methods return a DataFrame so that another pandas method can be applied to the result. This improves readability of code.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df = (pd.melt(df).rename(columns={'variable':'var','value':'val'}).query('val >= 200'))",
      "metadata": {
        "trusted": true
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Reshapin Data\n##### Change layout, sorting, reindexing, renaming",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "pd.melt(df)                                #Gather columns into rows.\ndf.pivot(columns='var', values='val')      #Spread rows into columns.\npd.concat([df1,df2])                       #Append rows of DataFrames\npd.concat([df1,df2], axis=1)               #Append columns of DataFrames\ndf.sort_values('mpg')                      #Order rows by values of a column (low to high).\ndf.sort_values('mpg', ascending=False)     #Order rows by values of a column (high to low).\ndf.rename(columns = {'y':'year'})          #Rename the columns of a DataFrame\ndf.sort_index()                            #Sort the index of a DataFrame\ndf.reset_index()                           #Reset index of DataFrame to row numbers, moving index to columns.\ndf.drop(columns=['Length', 'Height'])      #Drop columns from DataFrame",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Subset Observations - rows",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df[df.Length > 7]                         #Extract rows that meet logical criteria.\ndf.drop_duplicates()                      #Remove duplicate rows (only considers columns).\ndf.sample(frac=0.5)                       #Randomly select fraction of rows.\ndf.sample(n=10)                           #Randomly select n rows.\ndf.nlargest(n, 'value')                   #Select and order top n entries.\ndf.nsmallest(n, 'value')                  #Select and order bottom n entries.\ndf.head(n)                                #Select first n rows.\ndf.tail(n)                                #Select last n rows.",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Subset Variables - columns",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df[['width', 'length', 'species']]      #Select multiple columns with specific names.\ndf['width'] or df.width                 #Select single column with specific name.\ndf.filter(regex='regex')                #Select columns whose name matches regular expression regex.",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Using query\n##### query() allows Boolean expressions for filtering rows.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Subsets - rows and columns\n##### Use df.loc[] and df.iloc[] to select only rows, only columns or both.\n##### Use df.at[] and df.iat[] to access a single value by row and column.\n##### First index selects rows, second index columns.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.iloc[10:20]                                #Select rows 10-20.\ndf.iloc[:, [1, 2, 5]]                         #Select columns in positions 1, 2 and 5 (first column is 0).\ndf.loc[:, 'x2':'x4']                          #Select all columns between x2 and x4 (inclusive).\ndf.loc[df['a'] > 10, ['a', 'c']]              #Select rows meeting logical condition, and only the specific columns .\ndf.iat[1, 2]                                  #Access single value by index\ndf.at[4, 'A']                                 #Access single value by label",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "#### Logic in Python (and pandas)",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df1 = pd.DataFrame()\nS = ['<', '>', '==','<=','>=']\nSI = ['less than', 'geater than', 'equals','less than or equals','greater than or equals']\nS2 = ['!=', 'df.column.isin(values)', 'pd.isnull(obj)','pd.notnull(obj)','&,|,~,^,df.any(),df.all()']\nS3 = ['not equal to','group membership', 'is NaN', 'is not NaN','Logical and, or, not, xor, any, all']\n\ndf1['Signo'] = S\ndf1['Significado'] = SI\ndf1['Codigo'] = S2\ndf1['Respuesta'] = S3\n \n# display table\nprint(df1)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 17,
      "outputs": [
        {
          "name": "stdout",
          "text": "  Signo             Significado                     Codigo  \\\n0     <               less than                         !=   \n1     >             geater than     df.column.isin(values)   \n2    ==                  equals             pd.isnull(obj)   \n3    <=     less than or equals            pd.notnull(obj)   \n4    >=  greater than or equals  &,|,~,^,df.any(),df.all()   \n\n                             Respuesta  \n0                         not equal to  \n1                     group membership  \n2                               is NaN  \n3                           is not NaN  \n4  Logical and, or, not, xor, any, all  \n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "#### regex (Regular Expresions) Examples",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df2 = pd.DataFrame()\nM = ['\\.', 'Length$', '^Sepal','^x[1-5]$','^(?!Species$).*']\nMI = ['Matches strings containing a period \".\"', 'Matches strings ending with word \"Length\"', 'Matches strings beginning with the word \"Sepal\"',\n      'Matches strings beginning with \"x\" and ending with 1,2,3,4,5','Matches strings except the string \"Species\"']\n\ndf2['Expresion'] = M\ndf2['Significado'] = MI\n\n \n# display table\nprint(df2)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 19,
      "outputs": [
        {
          "name": "stdout",
          "text": "         Expresion                                        Significado\n0               \\.            Matches strings containing a period \".\"\n1          Length$          Matches strings ending with word \"Length\"\n2           ^Sepal    Matches strings beginning with the word \"Sepal\"\n3         ^x[1-5]$  Matches strings beginning with \"x\" and ending ...\n4  ^(?!Species$).*        Matches strings except the string \"Species\"\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "## Sumarize Data",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df['w'].value_counts()            #Count number of rows with each unique value of variable\nlen(df)                           #Number of rows in DataFrame.\ndf.shape                          #Tuple of # of rows, # of columns in DataFrame.\ndf['w'].nunique()                 #Number of distinct values in a column.\ndf.describe()                     #Basic descriptive and statistics for each column (or GroupBy).",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "##### pandas provides a large set of summary functions that operate on different kinds of pandas objects (DataFrame columns, Series, GroupBy, Expanding and Rolling (see below)) and produce single values for each of the groups. When applied to a DataFrame, the result is returned as a pandas Series for each column. Examples:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "sum()                             #Sum values of each object.\ncount()                           #Count non-NA/null values of each object.\nmedian()                          #Median value of each object.\nquantile([0.25,0.75])             #Quantiles of each object.\napply(function)                   #Apply function to each object.\nmin()                             #Minimum value in each object.\nmax()                             #Maximum value in each object.\nmean()                            #Mean value of each object.\nvar()                             #Variance of each object.\nstd()                             #Standard deviation of each object.",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Handling Missing Data",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.dropna() #Drop rows with any column having NA/null data.\ndf.fillna(value) #Replace all NA/null data with value.",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Make New Columns",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.assign(Area=lambda df: df.Length*df.Height) #Compute and append one or more new columns.\ndf['Volume'] = df.Length*df.Height*df.Depth    #Add single column.\npd.qcut(df.col, n, labels=False)               #Bin column into n buckets.",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "##### pandas provides a large set of vector functions that operate on all columns of a DataFrame or a single selected column (a pandas Series). These functions produce vectors of values for each of the columns, or a single Series for the individual Series. Examples:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "max(axis=1)                                   #Element-wise max.\nclip(lower=-10,upper=10)                      #Trim values at input thresholds\n\nmin(axis=1)                                   #Element-wise min.\nabs()                                         #Absolute value.",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Goup Data",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.groupby(by=\"col\")                          #Return a GroupBy object, grouped by values in column named \"col\".\ndf.groupby(level=\"ind\")                       #Return a GroupBy object, grouped by values in index level named \"ind\".",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "##### All of the summary functions listed above can be applied to a group.\n##### Additional GroupBy functions:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "size()                                        #Size of each group.\nagg(function)                                 #Aggregate group using function.",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "##### The examples below can also be applied to groups. In this case, the function is applied on a per-group basis, and the returned vectors are of the length of the original DataFrame.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "shift(1)                                      #Copy with values shifted by 1.\nrank(method='dense')                          #Ranks with no gaps.\nrank(method='min')                            #Ranks. Ties get min rank.\nrank(pct=True)                                #Ranks rescaled to interval [0, 1].\nrank(method='first')                          #Ranks. Ties go to first value.\n\nshift(-1)                                     #Copy with values lagged by 1.\ncumsum()                                      #Cumulative sum.\ncummax()                                      #Cumulative max.\ncummin()                                      #Cumulative min.\ncumprod()                                     #Cumulative product.",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Windows",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.expanding()                                #Return an Expanding object allowing summary functions to be applied cumulatively.\ndf.rolling(n)                                 #Return a Rolling object allowing summary functions to be applied to windows of length n.",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Ploting",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.plot.hist()                               #Histogram for each column\ndf.plot.scatter(x='w',y='h')                 #Scatter chart using pairs of points",
      "metadata": {
        "trusted": true
      },
      "execution_count": 20,
      "outputs": [
        {
          "ename": "<class 'ImportError'>",
          "evalue": "matplotlib is required for plotting when the default backend \"matplotlib\" is selected.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m                               \u001b[38;5;66;03m#Histogram for each column\u001b[39;00m\n\u001b[1;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mplot\u001b[38;5;241m.\u001b[39mscatter(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m,y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m'\u001b[39m)                 \u001b[38;5;66;03m#Scatter chart using pairs of points\u001b[39;00m\n",
            "File \u001b[0;32m/lib/python3.11/site-packages/pandas/plotting/_core.py:1374\u001b[0m, in \u001b[0;36mPlotAccessor.hist\u001b[0;34m(self, by, bins, **kwargs)\u001b[0m\n\u001b[1;32m   1314\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhist\u001b[39m(\u001b[38;5;28mself\u001b[39m, by\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, bins: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PlotAccessor:\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;124;03m    Draw one histogram of the DataFrame's columns.\u001b[39;00m\n\u001b[1;32m   1317\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;124;03m        >>> ax = df.plot.hist(column=[\"age\"], by=\"gender\", figsize=(10, 8))\u001b[39;00m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1374\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhist\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/lib/python3.11/site-packages/pandas/plotting/_core.py:920\u001b[0m, in \u001b[0;36mPlotAccessor.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 920\u001b[0m     plot_backend \u001b[38;5;241m=\u001b[39m \u001b[43m_get_plot_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbackend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    922\u001b[0m     x, y, kind, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_call_args(\n\u001b[1;32m    923\u001b[0m         plot_backend\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent, args, kwargs\n\u001b[1;32m    924\u001b[0m     )\n\u001b[1;32m    926\u001b[0m     kind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kind_aliases\u001b[38;5;241m.\u001b[39mget(kind, kind)\n",
            "File \u001b[0;32m/lib/python3.11/site-packages/pandas/plotting/_core.py:1886\u001b[0m, in \u001b[0;36m_get_plot_backend\u001b[0;34m(backend)\u001b[0m\n\u001b[1;32m   1883\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend_str \u001b[38;5;129;01min\u001b[39;00m _backends:\n\u001b[1;32m   1884\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _backends[backend_str]\n\u001b[0;32m-> 1886\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43m_load_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1887\u001b[0m _backends[backend_str] \u001b[38;5;241m=\u001b[39m module\n\u001b[1;32m   1888\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\n",
            "File \u001b[0;32m/lib/python3.11/site-packages/pandas/plotting/_core.py:1817\u001b[0m, in \u001b[0;36m_load_backend\u001b[0;34m(backend)\u001b[0m\n\u001b[1;32m   1815\u001b[0m         module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas.plotting._matplotlib\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1816\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m-> 1817\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m   1818\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatplotlib is required for plotting when the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1819\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault backend \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is selected.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1820\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m   1821\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m module\n\u001b[1;32m   1823\u001b[0m found_backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "\u001b[0;31mImportError\u001b[0m: matplotlib is required for plotting when the default backend \"matplotlib\" is selected."
          ],
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "## Combine Data Sets\n##### Standard Joins",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "pd.merge(adf, bdf,how='left', on='x1')                   #Join matching rows from bdf to adf.\npd.merge(adf, bdf,how='right', on='x1')                  #Join matching rows from adf to bdf.\npd.merge(adf, bdf,how='inner', on='x1')                  #Join data. Retain only rows in both sets.\npd.merge(adf, bdf,how='outer', on='x1')                  #Join data. Retain all values, all rows.",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "##### Filtering Joins",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "adf[adf.x1.isin(bdf.x1)]                                #All rows in adf that have a match in bdf.\nadf[~adf.x1.isin(bdf.x1)]                               #All rows in adf that do not have a match in bdf.",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "##### Set-like Operations",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "pd.merge(ydf, zdf)                                      #Rows that appear in both ydf and zdf (Intersection).\npd.merge(ydf, zdf, how='outer')                         #Rows that appear in either or both ydf and zdf (Union).\npd.merge(ydf, zdf, how='outer',indicator=True)\n.query('_merge == \"left_only\"')\n.drop(columns=['_merge'])                               #Rows that appear in ydf but not zdf (Setdiff).",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}