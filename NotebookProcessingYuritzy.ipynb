{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e126eb38",
   "metadata": {},
   "source": [
    "## Notebook Processing\n",
    "### Yuritzy Pérez 14/09/2023\n",
    "#### Basado en:\n",
    "#### Automated Data Cleaning with Python: Elise Landman\n",
    "##### How to automate data preparation and save time on your next data science project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f2971e",
   "metadata": {},
   "source": [
    "### ¿Qué queremos automatizar?\n",
    "#### Los pasos que se deben automatizar son aquellos que se repiten constantemente en casi todos los proyectos de ciencia de datos. Lo que se construirá es necesario que sea válido para varios datasets para que pueda ser útil en distintos contextos. Por ejemplo, existen tareas repetidas en las mayorias de los proyectos como lo son revisar formato de los datos, tipos de datos, datos faltantes o si hay outliers. \n",
    "### Construcción\n",
    "#### Se importan las librerias que se utilizaran en el proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f1ce195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import isnan\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3366ecbd",
   "metadata": {},
   "source": [
    "#### Definiremos que nuestro script tomará un marco de datos Pandas como entrada, lo que significa que necesitamos al menos transformar los datos a un formato de marco de datos Pandas antes de que puedan ser procesados por nuestro pipeline.\n",
    "\n",
    "#### Ahora veamos los bloques de construcción de nuestro pipeline. Los siguientes capítulos recorrerán los siguientes pasos de procesamiento:\n",
    "#### [Bloque 1] Valores faltantes\n",
    "#### [Bloque 2] Valores atípicos\n",
    "#### [Bloque 3] Codificación categórica\n",
    "#### [Bloque 4] Extracción de características de fecha y hora\n",
    "#### [Bloque 5] Pasos de pulido\n",
    "\n",
    "### Valores Faltantes\n",
    "#### Es muy común que un dataset tenga datos faltantes por lo que se deberá elegir que hacer con ellos, se pueden eliminar, usar tecnicas de imputación o predecir valores por medio de regresiones o clasificación. Las técnicas de imputación sustituyen los datos que faltan por determinados valores, como la media, o por un valor similar a otros valores de muestra en el espacio de características.\n",
    "\n",
    "#### La elección de cómo tratar los valores que faltan dependerá sobre todo de: el tipo de datos (numéricos o categóricos) y el número de valores que faltan en relación con el número total de muestras (eliminar 1 observación de 100k tendrá un impacto diferente que eliminar 1 de 100).\n",
    "\n",
    "#### El código seguirá la estrategia imputación > eliminación, y soportará las siguientes técnicas: predicción con Regresión Lineal y Logística, imputación con K-NN, media, mediana y moda, así como eliminación.\n",
    "\n",
    "#### Descripción de la función: Primero crearemos una clase separada para manejar los valores perdidos. La función que manejamos a continuación tratará los valores perdidos numéricos y categóricos de forma diferente: algunas técnicas de imputación pueden ser aplicables sólo para datos numéricos, mientras que otras sólo para datos categóricos. Veamos la primera parte de la función, que se ocupa de las características numéricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5e1293",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MissingValues:\n",
    "\n",
    "    def handle(self, df, _n_neighbors=3):\n",
    "        # function for handling missing values in the data\n",
    "        if self.missing_num or self.missing_categ:\n",
    "            logger.info('Started handling of missing values...', str(self.missing_num).upper())\n",
    "            start = timer()\n",
    "            self.count_missing = df.isna().sum().sum()\n",
    "\n",
    "            if self.count_missing != 0:\n",
    "                logger.info('Found a total of {} missing value(s)', self.count_missing)\n",
    "                df = df.dropna(how='all')\n",
    "                df.reset_index(drop=True)\n",
    "                \n",
    "                if self.missing_num: # numeric data\n",
    "                    logger.info('Started handling of NUMERICAL missing values... Method: \"{}\"', str(self.missing_num).upper())\n",
    "                    # automated handling\n",
    "                    if self.missing_num == 'auto': \n",
    "                        self.missing_num = 'linreg'\n",
    "                        lr = LinearRegression()\n",
    "                        df = MissingValues._lin_regression_impute(self, df, lr)\n",
    "                        self.missing_num = 'knn'\n",
    "                        imputer = KNNImputer(n_neighbors=_n_neighbors)\n",
    "                        df = MissingValues._impute(self, df, imputer, type='num')\n",
    "                    # linear regression imputation\n",
    "                    elif self.missing_num == 'linreg':\n",
    "                        lr = LinearRegression()\n",
    "                        df = MissingValues._lin_regression_impute(self, df, lr)\n",
    "                    # knn imputation\n",
    "                    elif self.missing_num == 'knn':\n",
    "                        imputer = KNNImputer(n_neighbors=_n_neighbors)\n",
    "                        df = MissingValues._impute(self, df, imputer, type='num')\n",
    "                    # mean, median or mode imputation\n",
    "                    elif self.missing_num in ['mean', 'median', 'most_frequent']:\n",
    "                        imputer = SimpleImputer(strategy=self.missing_num)\n",
    "                        df = MissingValues._impute(self, df, imputer, type='num')\n",
    "                    # delete missing values\n",
    "                    elif self.missing_num == 'delete':\n",
    "                        df = MissingValues._delete(self, df, type='num')\n",
    "                        logger.debug('Deletion of {} NUMERIC missing value(s) succeeded', self.count_missing-df.isna().sum().sum())      \n",
    "\n",
    "                if self.missing_categ: # categorical data\n",
    "                    logger.info('Started handling of CATEGORICAL missing values... Method: \"{}\"', str(self.missing_categ).upper())\n",
    "                    # automated handling\n",
    "                    if self.missing_categ == 'auto':\n",
    "                        self.missing_categ = 'logreg'\n",
    "                        lr = LogisticRegression()\n",
    "                        df = MissingValues._log_regression_impute(self, df, lr)\n",
    "                        self.missing_categ = 'knn'\n",
    "                        imputer = KNNImputer(n_neighbors=_n_neighbors)\n",
    "                        df = MissingValues._impute(self, df, imputer, type='categ')\n",
    "                    elif self.missing_categ == 'logreg':\n",
    "                        lr = LogisticRegression()\n",
    "                        df = MissingValues._log_regression_impute(self, df, lr)\n",
    "                    # knn imputation\n",
    "                    elif self.missing_categ == 'knn':\n",
    "                        imputer = KNNImputer(n_neighbors=_n_neighbors)\n",
    "                        df = MissingValues._impute(self, df, imputer, type='categ')  \n",
    "                    # mode imputation\n",
    "                    elif self.missing_categ == 'most_frequent':\n",
    "                        imputer = SimpleImputer(strategy=self.missing_categ)\n",
    "                        df = MissingValues._impute(self, df, imputer, type='categ')\n",
    "                    # delete missing values                    \n",
    "                    elif self.missing_categ == 'delete':\n",
    "                        df = MissingValues._delete(self, df, type='categ')\n",
    "                        logger.debug('Deletion of {} CATEGORICAL missing value(s) succeeded', self.count_missing-df.isna().sum().sum())\n",
    "            else:\n",
    "                logger.debug('{} missing values found', self.count_missing)\n",
    "            end = timer()\n",
    "            logger.info('Completed handling of missing values in {} seconds', round(end-start, 6))  \n",
    "        else:\n",
    "            logger.info('Skipped handling of missing values')\n",
    "        return df\n",
    "\n",
    "    def _impute(self, df, imputer, type):\n",
    "        # function for imputing missing values in the data\n",
    "        cols_num = df.select_dtypes(include=np.number).columns \n",
    "\n",
    "        if type == 'num':\n",
    "            # numerical features\n",
    "            for feature in df.columns: \n",
    "                if feature in cols_num:\n",
    "                    if df[feature].isna().sum().sum() != 0:\n",
    "                        try:\n",
    "                            df_imputed = pd.DataFrame(imputer.fit_transform(np.array(df[feature]).reshape(-1, 1)))\n",
    "                            counter = df[feature].isna().sum().sum() - df_imputed.isna().sum().sum()\n",
    "\n",
    "                            if (df[feature].fillna(-9999) % 1  == 0).all():\n",
    "                                df[feature] = df_imputed\n",
    "                                # round back to INTs, if original data were INTs\n",
    "                                df[feature] = df[feature].round()\n",
    "                                df[feature] = df[feature].astype('Int64')                                        \n",
    "                            else:\n",
    "                                df[feature] = df_imputed\n",
    "                            if counter != 0:\n",
    "                                logger.debug('{} imputation of {} value(s) succeeded for feature \"{}\"', str(self.missing_num).upper(), counter, feature)\n",
    "                        except:\n",
    "                            logger.warning('{} imputation failed for feature \"{}\"', str(self.missing_num).upper(), feature)\n",
    "        else:\n",
    "            # categorical features\n",
    "            for feature in df.columns:\n",
    "                if feature not in cols_num:\n",
    "                    if df[feature].isna().sum()!= 0:\n",
    "                        try:\n",
    "                            mapping = dict()\n",
    "                            mappings = {k: i for i, k in enumerate(df[feature].dropna().unique(), 0)}\n",
    "                            mapping[feature] = mappings\n",
    "                            df[feature] = df[feature].map(mapping[feature])\n",
    "\n",
    "                            df_imputed = pd.DataFrame(imputer.fit_transform(np.array(df[feature]).reshape(-1, 1)), columns=[feature])    \n",
    "                            counter = sum(1 for i, j in zip(list(df_imputed[feature]), list(df[feature])) if i != j)\n",
    "\n",
    "                            # round to integers before mapping back to original values\n",
    "                            df[feature] = df_imputed\n",
    "                            df[feature] = df[feature].round()\n",
    "                            df[feature] = df[feature].astype('Int64')  \n",
    "\n",
    "                            # map values back to original\n",
    "                            mappings_inv = {v: k for k, v in mapping[feature].items()}\n",
    "                            df[feature] = df[feature].map(mappings_inv)\n",
    "                            if counter != 0:\n",
    "                                logger.debug('{} imputation of {} value(s) succeeded for feature \"{}\"', self.missing_categ.upper(), counter, feature)\n",
    "                        except:\n",
    "                            logger.warning('{} imputation failed for feature \"{}\"', str(self.missing_categ).upper(), feature)\n",
    "        return df\n",
    "\n",
    "    def _lin_regression_impute(self, df, model):\n",
    "        # function for predicting missing values with linear regression\n",
    "        cols_num = df.select_dtypes(include=np.number).columns\n",
    "        mapping = dict()\n",
    "        for feature in df.columns:\n",
    "            if feature not in cols_num:\n",
    "                # create label mapping for categorical feature values\n",
    "                mappings = {k: i for i, k in enumerate(df[feature])}\n",
    "                mapping[feature] = mappings\n",
    "                df[feature] = df[feature].map(mapping[feature])\n",
    "        for feature in cols_num: \n",
    "                try:\n",
    "                    test_df = df[df[feature].isnull()==True].dropna(subset=[x for x in df.columns if x != feature])\n",
    "                    train_df = df[df[feature].isnull()==False].dropna(subset=[x for x in df.columns if x != feature])\n",
    "                    if len(test_df.index) != 0:\n",
    "                        pipe = make_pipeline(StandardScaler(), model)\n",
    "\n",
    "                        y = np.log(train_df[feature]) # log-transform the data\n",
    "                        X_train = train_df.drop(feature, axis=1)\n",
    "                        test_df.drop(feature, axis=1, inplace=True)\n",
    "                        \n",
    "                        try:\n",
    "                            model = pipe.fit(X_train, y)\n",
    "                        except:\n",
    "                            y = train_df[feature] # use non-log-transformed data\n",
    "                            model = pipe.fit(X_train, y)\n",
    "                        if (y == train_df[feature]).all():\n",
    "                            pred = model.predict(test_df)\n",
    "                        else:\n",
    "                            pred = np.exp(model.predict(test_df)) # predict values\n",
    "\n",
    "                        test_df[feature]= pred\n",
    "\n",
    "                        if (df[feature].fillna(-9999) % 1  == 0).all():\n",
    "                            # round back to INTs, if original data were INTs\n",
    "                            test_df[feature] = test_df[feature].round()\n",
    "                            test_df[feature] = test_df[feature].astype('Int64')\n",
    "                            df[feature].update(test_df[feature])                          \n",
    "                        else:\n",
    "                            df[feature].update(test_df[feature])  \n",
    "                        logger.debug('LINREG imputation of {} value(s) succeeded for feature \"{}\"', len(pred), feature)\n",
    "                except:\n",
    "                    logger.warning('LINREG imputation failed for feature \"{}\"', feature)\n",
    "        for feature in df.columns: \n",
    "            try:   \n",
    "                # map categorical feature values back to original\n",
    "                mappings_inv = {v: k for k, v in mapping[feature].items()}\n",
    "                df[feature] = df[feature].map(mappings_inv)\n",
    "            except:\n",
    "                pass\n",
    "        return df\n",
    "\n",
    "    def _log_regression_impute(self, df, model):\n",
    "        # function for predicting missing values with logistic regression\n",
    "        cols_num = df.select_dtypes(include=np.number).columns\n",
    "        mapping = dict()\n",
    "        for feature in df.columns:\n",
    "            if feature not in cols_num:\n",
    "                # create label mapping for categorical feature values\n",
    "                mappings = {k: i for i, k in enumerate(df[feature])} #.dropna().unique(), 0)}\n",
    "                mapping[feature] = mappings\n",
    "                df[feature] = df[feature].map(mapping[feature])\n",
    "\n",
    "        target_cols = [x for x in df.columns if x not in cols_num]\n",
    "            \n",
    "        for feature in df.columns: \n",
    "            if feature in target_cols:\n",
    "                try:\n",
    "                    test_df = df[df[feature].isnull()==True].dropna(subset=[x for x in df.columns if x != feature])\n",
    "                    train_df = df[df[feature].isnull()==False].dropna(subset=[x for x in df.columns if x != feature])\n",
    "                    if len(test_df.index) != 0:\n",
    "                        pipe = make_pipeline(StandardScaler(), model)\n",
    "\n",
    "                        y = train_df[feature]\n",
    "                        train_df.drop(feature, axis=1, inplace=True)\n",
    "                        test_df.drop(feature, axis=1, inplace=True)\n",
    "\n",
    "                        model = pipe.fit(train_df, y)\n",
    "                        \n",
    "                        pred = model.predict(test_df) # predict values\n",
    "                        test_df[feature]= pred\n",
    "\n",
    "                        if (df[feature].fillna(-9999) % 1  == 0).all():\n",
    "                            # round back to INTs, if original data were INTs\n",
    "                            test_df[feature] = test_df[feature].round()\n",
    "                            test_df[feature] = test_df[feature].astype('Int64')\n",
    "                            df[feature].update(test_df[feature])                             \n",
    "                        logger.debug('LOGREG imputation of {} value(s) succeeded for feature \"{}\"', len(pred), feature)\n",
    "                except:\n",
    "                    logger.warning('LOGREG imputation failed for feature \"{}\"', feature)\n",
    "        for feature in df.columns: \n",
    "            try:\n",
    "                # map categorical feature values back to original\n",
    "                mappings_inv = {v: k for k, v in mapping[feature].items()}\n",
    "                df[feature] = df[feature].map(mappings_inv)\n",
    "            except:\n",
    "                pass     \n",
    "        return df\n",
    "\n",
    "    def _delete(self, df, type):\n",
    "        # function for deleting missing values\n",
    "        cols_num = df.select_dtypes(include=np.number).columns \n",
    "        if type == 'num':\n",
    "            # numerical features\n",
    "            for feature in df.columns: \n",
    "                if feature in cols_num:\n",
    "                    df = df.dropna(subset=[feature])\n",
    "                    df.reset_index(drop=True)\n",
    "        else:\n",
    "            # categorical features\n",
    "            for feature in df.columns:\n",
    "                if feature not in cols_num:\n",
    "                    df = df.dropna(subset=[feature])\n",
    "                    df.reset_index(drop=True)\n",
    "        return df    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31577342",
   "metadata": {},
   "source": [
    "#### Esta función comprueba qué método de tratamiento se ha elegido para las características numéricas y categóricas. El ajuste por defecto es \"auto\", lo que significa que los valores numéricos perdidos se imputarán primero mediante predicción con Regresión Lineal, y los valores restantes se imputarán con K-NN los valores categóricos perdidos se imputarán primero mediante predicción con Regresión Logística, y los valores restantes se imputarán con K-NN.\n",
    "\n",
    "#### En el caso de las características categóricas, se aplica el mismo principio que el anterior, salvo que sólo admitiremos la imputación con Regresión logística, K-NN e imputación de modo. Cuando utilicemos K-NN, primero codificaremos nuestras características categóricas en números enteros, utilizaremos estas etiquetas para predecir nuestros valores perdidos y, finalmente, volveremos a asignar las etiquetas a sus valores originales.\n",
    "\n",
    "#### Dependiendo del método de manipulación elegido, la función handle llama a las funciones necesarias dentro de su clase para manipular los datos con la ayuda de varios paquetes de Sklearn: la función _impute se encargará de la imputación K-NN, media, mediana y modo, _lin_regression_impute y log_regression_impute realizarán la imputación a través de la predicción, y supongo que el papel de _delete se explica por sí mismo.\n",
    "\n",
    "#### La estructura final de nuestra clase MissingValues será la siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7779087",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MissingValues:\n",
    "    def handle(df, missing_num='auto', missing_categ='auto', _n_neighbors=3):\n",
    "        ...\n",
    "    def _impute(df, imputer, type):\n",
    "        ...\n",
    "    def _lin_regression_impute(df, model):\n",
    "        ...\n",
    "    def _log_regression_impute(df, model):\n",
    "        ...\n",
    "    def _delete(df, type):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d728d5",
   "metadata": {},
   "source": [
    "#### Después de haber terminado todos los pasos requeridos, nuestra función da salida a los datos de entrada procesados.\n",
    "\n",
    "### Valores atípicos\n",
    "#### Nuestro segundo bloque se centrará en el tratamiento de los valores atípicos en nuestros datos. Primero tenemos que preguntarnos: ¿cuándo consideramos que un valor es un valor atípico? Para nuestro pipeline, utilizaremos una regla comúnmente aplicada que dice que un punto de datos puede considerarse un valor atípico si se encuentra fuera del siguiente rango\n",
    "\n",
    "#### [Q1 - 1,5 * IQR ; Q3 + 1,5 * IQR]\n",
    "\n",
    " ##### donde Q1 y Q3 son los cuartiles 1 y 3 e IQR es el rango intercuartílico.\n",
    " \n",
    "#### Una vez definido qué es un valor atípico, debemos decidir cómo tratarlo. Existen de nuevo varias estrategias para hacerlo, y para nuestro caso de uso nos centraremos en las dos siguientes: winsorización y eliminación.\n",
    "\n",
    "##### La winsorización se utiliza en estadística para limitar los valores extremos de los datos y reducir el efecto de los valores atípicos sustituyéndolos por un percentil específico de los datos.\n",
    "\n",
    "#### Al utilizar winsorization, volveremos a utilizar nuestro rango definido anteriormente para reemplazar los valores atípicos:\n",
    "\n",
    "#### los valores > límite superior se sustituirán por el valor del rango superior y\n",
    "#### valores < límite inferior serán reemplazados por el valor del rango inferior.\n",
    "\n",
    "#### La estructura final de nuestra clase Outliers será la siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59086191",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Outliers:\n",
    "    # Function that handles outliers in the data\n",
    "    def handle(df, outliers='winz'):\n",
    "        if outliers:\n",
    "            if outliers == 'winz':  \n",
    "                df = Outliers._winsorization(self, df)\n",
    "            elif ourliers == 'delete':\n",
    "                df = Outliers._delete(self, df)\n",
    "        return df     \n",
    "    def _winsorization(df):\n",
    "        ...\n",
    "    def _delete(df):\n",
    "        ...\n",
    "    def _compute_bounds(df, feature):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4bce7f",
   "metadata": {},
   "source": [
    "### Configuración categórica\n",
    "#### Para poder realizar cálculos con datos categóricos, en la mayoría de los casos necesitamos que nuestros datos sean de tipo numérico, es decir, números o enteros. Por lo tanto, las técnicas más comunes consisten en codificar los datos de una sola vez o codificarlos con etiquetas.\n",
    "\n",
    "#### La codificación de datos en un solo paso representa cada valor único de una característica como un vector binario, mientras que la codificación de etiquetas asigna un número entero único a cada valor.\n",
    "\n",
    "#### Hay varios pros y contras para cada uno de los métodos, como por ejemplo el hecho de que la codificación de una sola vez produce muchas características adicionales. Además, si codificamos con etiquetas, éstas podrían ser interpretadas por ciertos algoritmos como matemáticamente dependientes: 1 manzana + 1 naranja = 1 plátano, lo que obviamente es una interpretación errónea de este tipo de datos categóricos.\n",
    "\n",
    "#### Estrategia por defecto 'auto' para realizar la codificación de acuerdo con las siguientes reglas:\n",
    "##### si la característica contiene < 10 valores únicos, se codificará de una sola vez\n",
    "##### si la característica contiene < 20 valores únicos, se codificará con etiquetas\n",
    "##### si la característica contiene más de 20 valores únicos, no se codificará.\n",
    "#### Se trata de una forma bastante primitiva y rápida de gestionar el proceso de codificación, que puede resultar útil, pero que también puede dar lugar a codificaciones no del todo apropiadas para nuestros datos. Aunque la automatización es genial, queremos asegurarnos de que también podemos definir manualmente qué características deben ser codificadas, y cómo. Esto se implementa en la función handle de la clase EncodeCateg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d6ab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodeCateg:\n",
    "    # Function for encoding of categorical features\n",
    "    # to specify columns set encode_categ to: ['auto', ['col1', col2']]\n",
    "    def handle(df, encode_categ=['auto']):\n",
    "        if encode_categ[0]:\n",
    "            # select non numeric features\n",
    "            cols_categ = set(df.columns) ^ set(df.select_dtypes(include=np.number).columns)\n",
    "            # check if all columns should be encoded\n",
    "            if len(encode_categ) == 1:\n",
    "                target_cols = cols_categ # encode ALL columns\n",
    "            else:\n",
    "                target_cols = encode_categ[1] # encode only specific columns\n",
    "            for feature in target_cols:\n",
    "                if feature in cols_categ:\n",
    "                    feature = feature # columns are column names\n",
    "                else:\n",
    "                    feature = df.columns[feature] # columns are indexes\n",
    "                try:\n",
    "                    # skip encoding of datetime features\n",
    "                    pd.to_datetime(df[feature])\n",
    "                except:\n",
    "                    try:\n",
    "                        if encode_categ[0] == 'auto':\n",
    "                            # ONEHOT encode if not more than 10 unique values to encode\n",
    "                            if df[feature].nunique() <=10:\n",
    "                                df = EncodeCateg._to_onehot(df, feature)\n",
    "                            # LABEL encode if not more than 20 unique values to encode\n",
    "                            elif df[feature].nunique() <=20:\n",
    "                                df = EncodeCateg._to_label(df, feature)\n",
    "                            # skip encoding if more than 20 unique values to encode\n",
    "                        elif encode_categ[0] == 'onehot':\n",
    "                            df = EncodeCateg._to_onehot(df, feature)\n",
    "                        elif encode_categ[0] == 'label':\n",
    "                            df = EncodeCateg._to_label(df, feature)\n",
    "                    except:\n",
    "                        pass\n",
    "        return df\n",
    "    def _to_onehot(df, feature, limit=10):\n",
    "        ...\n",
    "    def _to_label(df, feature):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb61f255",
   "metadata": {},
   "source": [
    "#### La función handle toma una lista como entrada, mientras que las características que queremos codificar manualmente pueden definirse mediante nombres de columnas o índices, como se indica a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1a3de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_categ = [‘onehot’, [‘column_name’, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46314ce",
   "metadata": {},
   "source": [
    "### Extracción de características de fecha y hora\n",
    "#### Si nuestro conjunto de datos contiene una característica que tiene valores de fecha y hora, como marcas de tiempo o fechas, es muy probable que queramos extraerlos para que sean más fáciles de manejar cuando los procesemos o visualicemos más adelante.\n",
    "#### También podemos hacerlo de forma automatizada: dejaremos que nuestro código busque entre las características y compruebe si alguna de ellas se puede convertir al tipo datetime. En caso afirmativo, podemos asumir con seguridad que esta característica contiene valores de fecha y hora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb701c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature for extracting datetime values\n",
    "def convert_datetime(df, extract_datetime='s'):\n",
    "    cols = set(df.columns) ^ set(df.select_dtypes(include=np.number).columns) \n",
    "    for feature in cols: \n",
    "        try:\n",
    "            # convert features encoded as strings to type datetime ['D','M','Y','h','m','s']\n",
    "            df[feature] = pd.to_datetime(df[feature], infer_datetime_format=True)\n",
    "            df['Day'] = pd.to_datetime(df[feature]).dt.day\n",
    "            if extract_datetime in ['M','Y','h','m','s']:\n",
    "                df['Month'] = pd.to_datetime(df[feature]).dt.month\n",
    "                if extract_datetime in ['Y','h','m','s']:\n",
    "                    df['Year'] = pd.to_datetime(df[feature]).dt.year\n",
    "                    if extract_datetime in ['h','m','s']:\n",
    "                        df['Hour'] = pd.to_datetime(df[feature]).dt.hour\n",
    "                        if extract_datetime in ['m','s']:\n",
    "                            df['Minute'] = pd.to_datetime(df[feature]).dt.minute\n",
    "                            if extract_datetime in ['s']:\n",
    "                              df['Sec'] = pd.to_datetime(df[feature]).dt.second\n",
    "            try: # check if entries for the extracted dates/times are valid, otherwise drop\n",
    "                if (df['Hour'] == 0).all() and (df['Minute'] == 0).all() and (df['Sec'] == 0).all():\n",
    "                    df.drop('Hour', inplace = True, axis =1 )\n",
    "                    df.drop('Minute', inplace = True, axis =1 )\n",
    "                    df.drop('Sec', inplace = True, axis =1 )\n",
    "                elif (df['Day'] == 0).all() and (df['Month'] == 0).all() and (df['Year'] == 0).all():\n",
    "                    df.drop('Day', inplace = True, axis =1 )\n",
    "                    df.drop('Month', inplace = True, axis =1 )\n",
    "                    df.drop('Year', inplace = True, axis =1 )  \n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693453c6",
   "metadata": {},
   "source": [
    "#### Podemos definir la granularidad con la que se extraen las características de fecha y hora, mientras que el valor predeterminado es 's' para segundos. Tras la extracción, la función comprueba si las entradas de fechas y horas tienen un significado válido: si las columnas extraídas 'Día', 'Mes' y 'Año' contienen todas 0's, se borrarán las tres. Lo mismo ocurre con \"Hora\", \"Minuto\" y \"Seg\".\n",
    "\n",
    "### Pulir Dataframe\n",
    "\n",
    "#### Ahora que hemos procesado nuestro conjunto de datos, todavía tenemos que hacer algunos ajustes para que nuestro marco de datos \"tenga buen aspecto\". ¿Qué quiero decir con esto?\n",
    "\n",
    "#### En primer lugar, algunas características que originalmente eran de tipo entero podrían haberse convertido en flotantes, debido a técnicas de imputación u otros pasos de procesamiento que se aplicaron. Antes de dar salida a nuestro marco de datos final, volveremos a convertir estos valores en enteros.\n",
    "\n",
    "#### En segundo lugar, queremos redondear todas las características flotantes de nuestro conjunto de datos al mismo número de decimales que tenían en nuestro conjunto de datos de entrada original. Esto es para evitar, por un lado, los innecesarios 0 finales en los decimales flotantes y, por otro, para asegurarnos de no redondear nuestros valores más que los valores originales.\n",
    "\n",
    "## Poniendo todo junto\n",
    "\n",
    "### Ejemplo de código con dataset\n",
    "#### El ejemplo que utilizaré para aplicar lo visto será con la fechas de mis datos, para ello usaré el código del artículo\n",
    "\n",
    "#### Comenzaremos cargando las librerías que se van a utilizar para los datos NetCDF. Primero convertiré mis variables a DataFrames de pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2b79c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\anaconda3\\Lib\\site-packages\\xarray\\coding\\times.py:254: RuntimeWarning: invalid value encountered in cast\n",
      "  flat_num_dates_ns_int = (flat_num_dates * _NS_PER_TIME_DELTA[delta]).astype(\n",
      "E:\\ProgramData\\anaconda3\\Lib\\site-packages\\xarray\\coding\\times.py:254: RuntimeWarning: invalid value encountered in cast\n",
      "  flat_num_dates_ns_int = (flat_num_dates * _NS_PER_TIME_DELTA[delta]).astype(\n",
      "E:\\ProgramData\\anaconda3\\Lib\\site-packages\\xarray\\coding\\times.py:254: RuntimeWarning: invalid value encountered in cast\n",
      "  flat_num_dates_ns_int = (flat_num_dates * _NS_PER_TIME_DELTA[delta]).astype(\n",
      "E:\\ProgramData\\anaconda3\\Lib\\site-packages\\xarray\\coding\\times.py:254: RuntimeWarning: invalid value encountered in cast\n",
      "  flat_num_dates_ns_int = (flat_num_dates * _NS_PER_TIME_DELTA[delta]).astype(\n",
      "E:\\ProgramData\\anaconda3\\Lib\\site-packages\\xarray\\coding\\times.py:254: RuntimeWarning: invalid value encountered in cast\n",
      "  flat_num_dates_ns_int = (flat_num_dates * _NS_PER_TIME_DELTA[delta]).astype(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                mean_observation_time\n",
      "line y            x                                  \n",
      "2    4.110367e+06 238455.893939                   NaT\n",
      "                  238655.881123                   NaT\n",
      "                  238855.868306                   NaT\n",
      "                  239055.855490                   NaT\n",
      "                  239255.842674                   NaT\n",
      "...                                               ...\n",
      "9    4.219560e+06 429043.680078                   NaT\n",
      "                  429243.667261                   NaT\n",
      "                  429443.654445                   NaT\n",
      "                  429643.641629                   NaT\n",
      "                  429843.628813                   NaT\n",
      "\n",
      "[4192208 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo NetCDF\n",
    "data = xr.open_dataset('dopplerscatt_20211020_140315.tomoL2CF.nc')\n",
    "\n",
    "# Seleccionamos la variable \"mean_observation_time\" que dio problemas para limpiarse durante la práctica anterior.\n",
    "variable_name = 'mean_observation_time'\n",
    "selected_variable = data[variable_name]\n",
    "\n",
    "# Convertimos la variable seleccionada a un DataFame\n",
    "df = selected_variable.to_dataframe()\n",
    "\n",
    "# imprimimos el DataFrame para observarlo\n",
    "print(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafe6810",
   "metadata": {},
   "source": [
    "#### Una vez que ya lo tenemos convetido, podemos aplicar el código del artículo, tal cual lo menciona, pero para nuestro Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b810fc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoClean process completed in 12.112933 seconds\n",
      "Logfile saved to: C:\\Users\\lic.-Ing.Yuri\\Documents\\ICD\\autoclean.log\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_observation_time</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-20 21:13:47.421569792</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-20 21:13:47.605900288</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-10-20 21:14:08.347603456</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-20 21:14:09.092011520</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-10-20 21:14:09.200946432</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657701</th>\n",
       "      <td>2021-10-20 23:50:05.804787712</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>23</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657702</th>\n",
       "      <td>2021-10-20 23:50:07.326255872</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>23</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657703</th>\n",
       "      <td>2021-10-20 23:50:04.906564352</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>23</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657704</th>\n",
       "      <td>2021-10-20 23:50:07.897048064</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>23</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657705</th>\n",
       "      <td>2021-10-20 23:50:11.187971584</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>23</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>657705 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean_observation_time  Day  Month  Year  Hour  Minute  Sec\n",
       "1      2021-10-20 21:13:47.421569792   20     10  2021    21      13   47\n",
       "2      2021-10-20 21:13:47.605900288   20     10  2021    21      13   47\n",
       "3      2021-10-20 21:14:08.347603456   20     10  2021    21      14    8\n",
       "4      2021-10-20 21:14:09.092011520   20     10  2021    21      14    9\n",
       "5      2021-10-20 21:14:09.200946432   20     10  2021    21      14    9\n",
       "...                              ...  ...    ...   ...   ...     ...  ...\n",
       "657701 2021-10-20 23:50:05.804787712   20     10  2021    23      50    5\n",
       "657702 2021-10-20 23:50:07.326255872   20     10  2021    23      50    7\n",
       "657703 2021-10-20 23:50:04.906564352   20     10  2021    23      50    4\n",
       "657704 2021-10-20 23:50:07.897048064   20     10  2021    23      50    7\n",
       "657705 2021-10-20 23:50:11.187971584   20     10  2021    23      50   11\n",
       "\n",
       "[657705 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from AutoClean import AutoClean\n",
    "pipeline = AutoClean(df)\n",
    "\n",
    "pipeline.output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dba525",
   "metadata": {},
   "source": [
    "#### Como se muestra, obtuvimos la variable 'mean_observation_time' en formato de fecha Gregoriana mediante una conversión desde 'Julian Date', utilizando el mismo código. Esta transformación fue necesaria para facilitar su uso en nuestro análisis y se realizó de forma más sencilla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af3a9f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<Axes: title={'center': 'mean_observation_time'}>]], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa814ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
